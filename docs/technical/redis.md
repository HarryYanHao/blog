---
sidebar: 'auto'
sidebarDepth: 1
pageClass: common
---
# Redis 深度历险
[[toc]]
## Redis 安装
:::tip
个人使用的是docker安装,安装方式简单
:::
```sh
docker pull redis
docker run --name myredis -d -p 6399:6379 redis
docker exec -it myredis /bin/bash
redis-cli
```
## Redis 基础数据结构
Redis有5种基础数据结构，分别为：String（字符串），hash（哈希），list（列表），set（集合），zset（有序集合）   
Redis所有的数据结构都是以唯一的key字段作为名称，然后通过这个唯一key值获取相应的value数据。
对同一个key存储不同的数据结构，redis会报`WRONGTYPE Operation against a key holding the wrong kind of value`错误信息
### string
字符串String是Redis最简单的数据结构。字符串结构使用非常广泛，一个常见的用途就是缓存用户信息。我们将用户信息结构体使用JSON序列化成字符串，然后将序列化后的字符串塞进Redis缓存。同样，获取用户信息会经过一次反序列化的过程。 
:::warning
字符串最大长度为512M
:::  
Redis的字符串是动态字符串，是可以修改的字符串,采用与分配冗余空间的方式来减少内存的频繁分配。capacity一般高于实际字符串长度len。当字符串长度小于1M时，扩容都是加倍现有的空间，超过1M时只会多扩1M的空间
### list
Redis的list数据结构是一种链表的结构，这意味着list的插入和删除操作非常快，时间复杂度为O(1)，但是索引定位很慢时间复杂度O(n) 当列表弹出最后一个元素，该数据结构自动被删除，内存被回收。   
慢操作   
lget lrange ltrim 都是复杂度O(n)操作   
双向指针可以实现类似 队列 栈 的数据结构操作   
### hash
hash结构是采用数组+链表二维结构，redis字典的值只能是字符串，Redis为了高性能不能采取堵塞rehash，所以使用的是渐进式的rehash策略，渐进式的rehash会在rehash的同时，保留新旧两个hash结构，然后在后续的定时任务中以及hash操作指令中，顺序渐进的将旧hash的值一点点的迁徙到新hash结构中，当搬迁完成了，就会使用新的hash结构取而代之  
当hash移除最后一个元素之后，该数据结构自动被删除，内存被回收
string和hash结构区别，hash可以根据字段单独存储，获取的时候可以部分获取。string只能存储所有序列化的数据。获取的时候需要一次性全部读取。比较消耗网络流量。hash存储的消耗肯定是高于string的。需要根据使用的实际的情况选择合适的存储结构。
### set
set结构内部的键值对是无序且唯一的   
当集合中最后一个元素移除之后，数据结构自动删除，内存被回收。   
eg：集合结构可以存储中奖用户id，因为有去重功能，可以保证一个用户不能中奖两次。在我们项目中可以存储委托，成交id    
常用的方法有 sdd smembers sismember scard#获取长度 spop#弹出一个
### zset
zset有序集合 一方面是一个set 保证了value的唯一性 另一方面提供了一个score字段 代表这个value的排序权重   
zset中最后一个元素移除之后，数据结构自动删除，内存被回收。
## 容器型数据结构通用规则
list/set/zset/hash 这四种数据结构是容器型数据结构 他们共享下面两条通用规则   

1.create if not exist   
如果容器不存在，那就创建一个，再进行操作。比如rpush，比如刚开始是没有列表的，则会自动创建一个，然后再rpush进去新元素     

2.drop if no elements    
如果容器内的最后一个元素被移除，容器消失，释放内存。    
## 过期时间
Redis所有的数据结构都可以设置过期时间，时间到了，redis会自动删除相应的对象。需要注意的是过期是以对象为单位即是以key为单位 不是以其中的子key。    
还有一点需要注意，如果你为某个key设置了过期时间，但是有用set修改了值，过期时间会消失。
## 分布式锁
分布式锁本质上要实现的目标就是在redis里面占位，当别的进程要来占时，发现已经有key值，只能放弃或者等待。   
占位一般是使用setnx(set if not exists)指令，只允许被一个客户端占位，先来先占，用完了之后使用del删除key释放位置。   
```sh
setnx lock:codehole true
do something
del lock:codehole
```
但是有个问题，如果执行逻辑中间出现了异常，可能导致del指令没有被调用，从而造成死锁，锁永远得不到释放。于是我们在拿到锁之后，再给锁加上一个过期时间，比如5s，这样即使中间出现异常也可以保证5s后锁会自动释放。
```sh
setnx lock:codehole true
expire lock:codehole 5
do something
del lock:codehole
```
但是以上逻辑还是有问题，如果setnx和expire之间不是原子指令。如果这两条指令可以一起执行就不会出现问题，并且这个问题无法使用redis事务的特性来解决 因为expire需要依赖于setnx的执行结果。如果setnx没有抢到锁，expire是不应被执行的。事务里没有if-else分支逻辑，事务的特点是一口气执行，要么一个都不执行。redis2.8版本后作者加入了set指令的扩展参数，使得setnx和expire指令可以一起执行，解决了分布式锁的乱象。   
```sh
set lock:codehole true ex 5 nx OK
do something
del lock:codehole
```
### 超时问题
redis的分布式锁不能解决超时问题，如果在加锁和释放锁之间的逻辑执行的太长，以至于超出了锁的限制，就会出现问题。因为这时候锁过期了，第二个线程重新持有了这把锁，但是第一个线程执行完了业务逻辑，就把锁给释放了，第三个线程就会在第二个线程执行完成之间拿到了锁。   
为了避免这个问题，Redis分布式锁不能用于较长时间的任务。如果真的偶尔出现了，数据出现的小波错乱可能需要人工介入解决。   
有一个更加安全的方案是set指令的value参数设置为一个随机数，释放时先匹配随机数是否一致，然后再删除key。但是匹配value和删除key不是一个原子操作，需要用Lua脚本来处理，Lua脚本可以保证连续多个指令的原子性执行。
### 可重入性
这里只解释概念，不推荐使用。可重入性是指线程在持有锁的情况下再次请求加锁，如果一个锁支持同一个线程多次加锁，那么这个锁就是可重入的。
## 延时队列
Redis的消息队列没有像Kafka和Rabbitmq那样多的高级特性，也没有ack保证，如果对消息的可靠性有着极致的追求，那么它就不适用。   
Redis的list（列表）数据结构常用来作为异步消息队列使用，使用rpush/lpush操作入队列，使用lpop和rpop来出队列。   
### 队列空了怎么办
客户端通过队列的pop操作来获取消息，然后进行处理，处理完了再接着获取消息，再进行处理。如此循环往复，这便是作为队列消费者的客户端的生命周期。   
可是如果队列空了，客户端就会陷入pop的死循环，不停地pop，没有数据，接着pop，有没有数据，浪费生命的空轮询。空轮询不但拉高了客户端的CPU，redis的QPS也会被拉高。    
通常我们使用sleep来解决这个问题，让线程睡一会，sleep(1) 不但客户端的CPU能降下来，Redis的QPS也降下来了。
### 队列延迟
用上面睡眠的方法可以解决问题，但是有个小问题，那就是睡眠会导致消息的延迟增大。如果只有一个消费者，那么这个延迟就是1s。如果有多个消费者，这个延迟会有所下降，因为每个消费者的睡眠时间是岔开的。
可以缩小延迟时间来降低延迟，也可以用`blpop/brpop`来解决，前缀字符b的意思是blocking 也就是阻塞读。   
阻塞读再队列没有数据的时候，会立即进入休眠状态，一旦数据到来，则立即醒过来。消息的延迟几乎为零，用`blpop/brpop`代替`lpop/rpop`就完美的解决了上述问题。
### 空闲连接自动断开
如果线程一直阻塞在那里，Redis 的客户端连接就成了闲置连接，闲置过久，服务器一般会主动断开连接，减少闲置资源占用。这个时候`blpop/brpop`会抛出异常。
所以编写客户端消费者的时候要小心，注意捕获异常，并且重试。
## 位图
在平时开发过程中，会有一些bool型的数据需要存储，比如用户一年的签到记录，签了为1，没签为0 要记录365天，如果使用普通key/value 再同时考虑用户数量，这个存储空间是惊人的。   
为了解决这个问题,Redis 提供了位图数据结构，这样每天的签到记录只占据一个位,365天就是365位，46个字节 （8bit=1Byte 1kb=1024B）  这样就大大的节约了储存空间。   
位图不是特殊的数据结构，它的内容其实就是普通的字符串，也就是byte数组。我们可以使用普通的 `get/set`直接获取和设置整个位图的内容，也可以使用位图操作`getbit/setbit`等将byte数组看成是’位数组‘来处理。
### 基本使用
Redis的位数组是自动扩展的，如果设置了某个偏移位置超出了现有的内容范围，就会自动将位数组进行零扩充。基本使用有零存零取，零存整取，整存零取。零存就是使用`setbit`，零取使用`getbit`，整取使用`get`，如果对应位的字节是不可打印的字符，redis-cli会显示该字符的16进制形式。
### 统计和查找
Redis 提供了位图的统计指令 bitcount和位图的查找指令bitpos，bitcount用来统计指定位置范围内1的个数，bitpos用来查找指定范围内出现的第一个0或1。如果制定了范围参数[start,end]就可以统计在某个时间范围内用户签到了多少天，遗憾的是start和end参数是字节索引，也就是说指定的范围必须是8的倍数，而不能任意指定。
## HyperLogLog
HyperLogLog也是redis提供的一种数据结构。这种数据结构就是用来解决统计问题，HyperLogLog提供不精确的去重技术方案，误差在0.81%，这种精度可以满足UV类的统计需求。   
### 使用方法
HyperLogLog提供了两个指令pfadd和pfcount，根据字面意义很好理解，一个是增加计数，一个是获取计数，pfadd用法和set集合的sadd是一样的，来一个用户ID,就将用户ID塞进去。pfcount和scard用法是一样的，直接获取计数量
```sh
pfadd hyperloglog user1
pfadd hyperloglog user2
pfcount hyperloglog #结果为2
pfadd hyperloglog user3
pfcount hyperloglog #结果为3
pfadd hyper harry
pfmerge hyperloglog hyper
pfcount hyperloglog #结果为4
```
### 注意事项
除了上述的两个命令外。还提供了三个指令，pfmerge，用于将多个pf计数值累加在一起形成一个新的pf值。HyperLogLog这个数据结构是需要花费代价的，它需占据一定的12k存储空间，所以它不适合统计单个用户相关的数据。如果用户量特别庞大的时候，相比set方案，这个数据结构用于统计uv还是非常值得的。
不过也不用过于担心，Redis对HyperLogLog的储存进行了优化，在技术比较小时，它的存储空间采用稀疏矩阵存储，空间占用很小，仅仅在计数慢慢变大，稀疏矩阵占用空间渐渐超过了阀值时，才会一次性转变成稠密矩阵，才会占用12k的空间。
